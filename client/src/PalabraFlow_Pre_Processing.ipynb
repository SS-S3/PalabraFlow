{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA2-kfLqhMJU",
        "outputId": "358e3446-3197-4cf4-8705-f54f380f97ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 13828501691889299298\n",
            "xla_global_id: -1\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p nmt\n",
        "%cd nmt\n",
        "!git clone https://github.com/ymoslem/MT-Preparation.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZRB0QmNhvFL",
        "outputId": "b54eb20a-751d-46e8-f0a4-5345180e290a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nmt\n",
            "Cloning into 'MT-Preparation'...\n",
            "remote: Enumerating objects: 319, done.\u001b[K\n",
            "remote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 319 (delta 33), reused 22 (delta 20), pack-reused 268 (from 2)\u001b[K\n",
            "Receiving objects: 100% (319/319), 93.77 KiB | 1.03 MiB/s, done.\n",
            "Resolving deltas: 100% (154/154), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -r MT-Preparation/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6keUmZRlh4mq",
        "outputId": "048fc780-ee6d-4e4f-8fda-15e5f4fa06d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r MT-Preparation/requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r MT-Preparation/requirements.txt (line 2)) (2.2.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r MT-Preparation/requirements.txt (line 3)) (0.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r MT-Preparation/requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r MT-Preparation/requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r MT-Preparation/requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->-r MT-Preparation/requirements.txt (line 2)) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://object.pouta.csc.fi/OPUS-tico-19/v2020-10-28/moses/en-es.txt.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHkpAeiHh9Gp",
        "outputId": "3e2b0522-228c-42b6-be72-2372d34ee4a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-14 09:01:34--  https://object.pouta.csc.fi/OPUS-tico-19/v2020-10-28/moses/en-es.txt.zip\n",
            "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.18, 86.50.254.19\n",
            "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 343223 (335K) [application/zip]\n",
            "Saving to: ‘en-es.txt.zip’\n",
            "\n",
            "en-es.txt.zip       100%[===================>] 335.18K   547KB/s    in 0.6s    \n",
            "\n",
            "2025-04-14 09:01:35 (547 KB/s) - ‘en-es.txt.zip’ saved [343223/343223]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip en-es.txt.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7ZKwB6qidGP",
        "outputId": "e45e874b-f438-4892-9d6a-16a518d4e0cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  en-es.txt.zip\n",
            "replace README? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: README                  \n",
            "replace LICENSE? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: LICENSE                 \n",
            "replace tico-19.en-es.en? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: tico-19.en-es.en        \n",
            "replace tico-19.en-es.es? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: tico-19.en-es.es        \n",
            "replace tico-19.en-es.xml? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: tico-19.en-es.xml       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 MT-Preparation/filtering/filter.py tico-19.en-es.en tico-19.en-es.es en es\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8bCfC-eifsr",
        "outputId": "b0d6580a-955a-4989-bed8-9aaac4b0051a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y\n",
            "Dataframe shape (rows, columns): (3071, 2)\n",
            "--- Rows with Empty Cells Deleted\t--> Rows: 3071\n",
            "--- Duplicates Deleted\t\t\t--> Rows: 3070\n",
            "--- Source-Copied Rows Deleted\t\t--> Rows: 3070\n",
            "--- Too Long Source/Target Deleted\t--> Rows: 3055\n",
            "--- HTML Removed\t\t\t--> Rows: 3055\n",
            "--- Rows will remain true-cased\t\t--> Rows: 3055\n",
            "--- Rows with Empty Cells Deleted\t--> Rows: 3055\n",
            "--- Rows Shuffled\t\t\t--> Rows: 3055\n",
            "--- Source Saved: tico-19.en-es.en-filtered.en\n",
            "--- Target Saved: tico-19.en-es.es-filtered.es\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls MT-Preparation/subwording/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCeqSgQsi2aH",
        "outputId": "3598db76-2328-425b-aac8-429e9075da48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1-train_bpe.py\t\t  1-train_unigram.py  3-desubword.py\n",
            "1-train_unigram_joint.py  2-subword.py\t      spm_to_vocab.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 MT-Preparation/subwording/1-train_unigram.py tico-19.en-es.es-filtered.es tico-19.en-es.en-filtered.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cn-eqCGyi9U7",
        "outputId": "cec8dc04-7fd2-4996-ef0b-19265a84f008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=tico-19.en-es.es-filtered.es --model_prefix=source --vocab_size=50000 --hard_vocab_limit=false --split_digits=true\n",
            "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: tico-19.en-es.es-filtered.es\n",
            "  input_format: \n",
            "  model_prefix: source\n",
            "  model_type: UNIGRAM\n",
            "  vocab_size: 50000\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 0.9995\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 1\n",
            "  pretokenization_delimiter: \n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  seed_sentencepieces_file: \n",
            "  hard_vocab_limit: 0\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 0\n",
            "  bos_id: 1\n",
            "  eos_id: 2\n",
            "  pad_id: -1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "  enable_differential_privacy: 0\n",
            "  differential_privacy_noise_level: 0\n",
            "  differential_privacy_clipping_threshold: 0\n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(185) LOG(INFO) Loading corpus: tico-19.en-es.es-filtered.es\n",
            "trainer_interface.cc(409) LOG(INFO) Loaded all 3055 sentences\n",
            "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(539) LOG(INFO) all chars count=531697\n",
            "trainer_interface.cc(550) LOG(INFO) Done: 99.9503% characters are covered.\n",
            "trainer_interface.cc(560) LOG(INFO) Alphabet size=78\n",
            "trainer_interface.cc(561) LOG(INFO) Final character coverage=0.999503\n",
            "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 3055 sentences.\n",
            "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
            "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=293901\n",
            "unigram_model_trainer.cc(312) LOG(INFO) Initialized 29453 seed sentencepieces\n",
            "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 3055\n",
            "trainer_interface.cc(609) LOG(INFO) Done! 12965\n",
            "unigram_model_trainer.cc(602) LOG(INFO) Using 12965 sentences for EM training\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=8848 obj=11.6661 num_tokens=27964 num_tokens/piece=3.16049\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=7734 obj=9.17624 num_tokens=28227 num_tokens/piece=3.64973\n",
            "trainer_interface.cc(687) LOG(INFO) Saving model: source.model\n",
            "trainer_interface.cc(699) LOG(INFO) Saving vocabs: source.vocab\n",
            "Done, training a SentencepPiece model for the Source finished successfully!\n",
            "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=tico-19.en-es.en-filtered.en --model_prefix=target --vocab_size=50000 --hard_vocab_limit=false --split_digits=true\n",
            "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: tico-19.en-es.en-filtered.en\n",
            "  input_format: \n",
            "  model_prefix: target\n",
            "  model_type: UNIGRAM\n",
            "  vocab_size: 50000\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 0.9995\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 1\n",
            "  pretokenization_delimiter: \n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  seed_sentencepieces_file: \n",
            "  hard_vocab_limit: 0\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 0\n",
            "  bos_id: 1\n",
            "  eos_id: 2\n",
            "  pad_id: -1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "  enable_differential_privacy: 0\n",
            "  differential_privacy_noise_level: 0\n",
            "  differential_privacy_clipping_threshold: 0\n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(185) LOG(INFO) Loading corpus: tico-19.en-es.en-filtered.en\n",
            "trainer_interface.cc(409) LOG(INFO) Loaded all 3055 sentences\n",
            "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(539) LOG(INFO) all chars count=454137\n",
            "trainer_interface.cc(550) LOG(INFO) Done: 99.9524% characters are covered.\n",
            "trainer_interface.cc(560) LOG(INFO) Alphabet size=75\n",
            "trainer_interface.cc(561) LOG(INFO) Final character coverage=0.999524\n",
            "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 3055 sentences.\n",
            "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
            "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=239214\n",
            "unigram_model_trainer.cc(312) LOG(INFO) Initialized 22899 seed sentencepieces\n",
            "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 3055\n",
            "trainer_interface.cc(609) LOG(INFO) Done! 12262\n",
            "unigram_model_trainer.cc(602) LOG(INFO) Using 12262 sentences for EM training\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=8066 obj=12.4752 num_tokens=28585 num_tokens/piece=3.54389\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=7018 obj=9.99782 num_tokens=28735 num_tokens/piece=4.09447\n",
            "trainer_interface.cc(687) LOG(INFO) Saving model: target.model\n",
            "trainer_interface.cc(699) LOG(INFO) Saving vocabs: target.vocab\n",
            "Done, training a SentencepPiece model for the Target finished successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pbh5Fwt-jKJx",
        "outputId": "062a1a82-0e99-4626-ac5a-ae3c673d7d7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "en-es.txt.zip\tsource.model  tico-19.en-es.en\t\t    tico-19.en-es.xml\n",
            "LICENSE\t\tsource.vocab  tico-19.en-es.en-filtered.en\n",
            "MT-Preparation\ttarget.model  tico-19.en-es.es\n",
            "README\t\ttarget.vocab  tico-19.en-es.es-filtered.es\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 MT-Preparation/subwording/2-subword.py source.model target.model tico-19.en-es.es-filtered.es tico-19.en-es.en-filtered.en\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMNomxIejOZu",
        "outputId": "547bfb8c-9395-43a7-8121-001b49359014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source Model: source.model\n",
            "Target Model: target.model\n",
            "Source Dataset: tico-19.en-es.es-filtered.es\n",
            "Target Dataset: tico-19.en-es.en-filtered.en\n",
            "Done subwording the source file! Output: tico-19.en-es.es-filtered.es.subword\n",
            "Done subwording the target file! Output: tico-19.en-es.en-filtered.en.subword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 3 tico-19.en-es.es-filtered.es && echo \"-----\" && head -n 3 tico-19.en-es.en-filtered.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vxI1MJkkTR9",
        "outputId": "ee66415f-60cb-434c-907a-b7ffc54f1a8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pueden dividirse en cuatro géneros, es decir, alfa, beta, gama y delta, de las cuales los alfacoronavirus y deltacoronavirus son los que infectan a los humanos.\n",
            "Rastrear los orígenes zoonóticos de los coronavirus de humanos brinda un marco para comprender la historia natural, la fuerza impulsora y los factores de restricción del salto entre especies.\n",
            "El HCoV-NL63 está asociado a la laringitis obstructiva, también conocida como crup.\n",
            "-----\n",
            "They can be divided into four genera, i.e., alpha, beta, gamma, and delta, of which alpha- and beta-CoVs are known to infect humans.\n",
            "Tracing the zoonotic origins of HCoVs provides a framework to understand the natural history, driving force and restriction factors of species jumping.\n",
            "HCoV-NL63 is associated with obstructive laryngitis, also known as croup.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!head -n 3 tico-19.en-es.es-filtered.es.subword && echo \"-----\" && head -n 3 tico-19.en-es.en-filtered.en.subword"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aW6-9-9gkWe6",
        "outputId": "7331562f-4057-4a60-ba80-9291e1e2175a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▁Puede n ▁dividi rse ▁en ▁cua tro ▁géneros , ▁es ▁decir , ▁alfa , ▁beta , ▁gam a ▁y ▁del ta , ▁de ▁la s ▁cual es ▁ los ▁alfacoronavirus ▁y ▁ deltacoronavirus ▁son ▁ los ▁que ▁infecta n ▁a ▁ los ▁humanos .\n",
            "▁Ra s tre ar ▁ los ▁ orí genes ▁zoonóticos ▁de ▁ los ▁coronavirus ▁de ▁humanos ▁brinda ▁un ▁marco ▁para ▁comprender ▁la ▁historia ▁natural , ▁la ▁fuerza ▁impulso ra ▁y ▁ los ▁factores ▁de ▁restric ción ▁del ▁sal to ▁entre ▁especies .\n",
            "▁El ▁HCoV - NL 6 3 ▁está ▁asociado ▁a ▁la ▁la ring itis ▁obstructiva , ▁también ▁conocida ▁como ▁c rup .\n",
            "-----\n",
            "▁The y ▁can ▁be ▁ divid ed ▁into ▁four ▁genera , ▁i . e . , ▁alpha , ▁beta , ▁gamma , ▁and ▁delta , ▁of ▁whi ch ▁alpha - ▁and ▁beta - CoVs ▁are ▁known ▁to ▁infect ▁humans .\n",
            "▁Trac ing ▁the ▁zoono tic ▁origins ▁of ▁HCoVs ▁provides ▁a ▁framework ▁to ▁understand ▁the ▁natural ▁history , ▁driv ing ▁force ▁and ▁restriction ▁factors ▁of ▁species ▁jump ing .\n",
            "▁HCoV - NL 6 3 ▁is ▁associated ▁with ▁ob structive ▁l aryng itis , ▁also ▁known ▁as ▁c roup .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 MT-Preparation/train_dev_split/train_dev_test_split.py 500 500 tico-19.en-es.es-filtered.es.subword tico-19.en-es.en-filtered.en.subword\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amc1k3uqkaQF",
        "outputId": "a6c1af04-651d-4867-d8d7-d9fd55c0a420"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframe shape: (3055, 2)\n",
            "--- Empty Cells Deleted --> Rows: 3055\n",
            "--- Wrote Files\n",
            "Done!\n",
            "Output files\n",
            "tico-19.en-es.es-filtered.es.subword.train\n",
            "tico-19.en-es.en-filtered.en.subword.train\n",
            "tico-19.en-es.es-filtered.es.subword.dev\n",
            "tico-19.en-es.en-filtered.en.subword.dev\n",
            "tico-19.en-es.es-filtered.es.subword.test\n",
            "tico-19.en-es.en-filtered.en.subword.test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l *.subword.*\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qpqBfjIkaNe",
        "outputId": "78207df9-fd4c-4e48-ba4e-2290d5608162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    500 tico-19.en-es.en-filtered.en.subword.dev\n",
            "    500 tico-19.en-es.en-filtered.en.subword.test\n",
            "   2055 tico-19.en-es.en-filtered.en.subword.train\n",
            "    500 tico-19.en-es.es-filtered.es.subword.dev\n",
            "    500 tico-19.en-es.es-filtered.es.subword.test\n",
            "   2055 tico-19.en-es.es-filtered.es.subword.train\n",
            "   6110 total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change this cell to print your name\n",
        "!echo -e \"My name is: FirstName SecondName \\n\"\n",
        "# -------------------------------------------\n",
        "\n",
        "!echo \"---First line---\"\n",
        "!head -n 1 *.{train,dev,test}\n",
        "\n",
        "!echo -e \"\\n---Last line---\"\n",
        "!tail -n 1 *.{train,dev,test}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUF7Z4mrkaK1",
        "outputId": "ee62b169-6559-440b-9dd2-75982c5bf032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My name is: FirstName SecondName \n",
            "\n",
            "---First line---\n",
            "==> tico-19.en-es.en-filtered.en.subword.train <==\n",
            "▁The y ▁can ▁be ▁ divid ed ▁into ▁four ▁genera , ▁i . e . , ▁alpha , ▁beta , ▁gamma , ▁and ▁delta , ▁of ▁whi ch ▁alpha - ▁and ▁beta - CoVs ▁are ▁known ▁to ▁infect ▁humans .\n",
            "\n",
            "==> tico-19.en-es.es-filtered.es.subword.train <==\n",
            "▁Puede n ▁dividi rse ▁en ▁cua tro ▁géneros , ▁es ▁decir , ▁alfa , ▁beta , ▁gam a ▁y ▁del ta , ▁de ▁la s ▁cual es ▁ los ▁alfacoronavirus ▁y ▁ deltacoronavirus ▁son ▁ los ▁que ▁infecta n ▁a ▁ los ▁humanos .\n",
            "\n",
            "==> tico-19.en-es.en-filtered.en.subword.dev <==\n",
            "▁ DAD ▁is ▁the ▁cause ▁of ▁ac ute ▁respirator y ▁distress ▁syndrome ▁( ARDS ) ▁and ▁severe ▁hypoxemia .\n",
            "\n",
            "==> tico-19.en-es.es-filtered.es.subword.dev <==\n",
            "▁El ▁ DAD ▁es ▁causante ▁del ▁síndrome ▁de ▁dificultad ▁respiratoria ▁aguda ▁( SDRA ) ▁y ▁de ▁hipox emia ▁grave .\n",
            "\n",
            "==> tico-19.en-es.en-filtered.en.subword.test <==\n",
            "▁do ▁you ▁have ▁some ▁short ness ▁of ▁breath ▁go es ▁with ▁that ?\n",
            "\n",
            "==> tico-19.en-es.es-filtered.es.subword.test <==\n",
            "▁¿ tiene ▁algunos ▁episodio s ▁de ▁falta ▁de ▁aire ▁con ▁eso ?\n",
            "\n",
            "---Last line---\n",
            "==> tico-19.en-es.en-filtered.en.subword.train <==\n",
            "▁On ▁ 1 1 ▁March , ▁Prim e ▁Minister ▁Conte ▁order ed ▁stopp age ▁of ▁near ly ▁all ▁commerc ial ▁activity ▁except ▁supermarkets ▁and ▁pharmacies . On ▁ 6 ▁March , ▁the ▁Ital ian ▁College ▁of ▁Ana es the sia , ▁Anal ges ia , ▁Re susc itation ▁and ▁In tensive ▁Care ▁( SI A A RTI ) ▁published ▁medical ▁ eth ic s ▁recommendations ▁regard ing ▁t riage ▁protocols ▁that ▁m ight ▁be ▁employed .\n",
            "\n",
            "==> tico-19.en-es.es-filtered.es.subword.train <==\n",
            "▁El ▁ 1 1 ▁de ▁marzo , ▁el ▁primer ▁ministro ▁Conte ▁orden ó ▁la ▁interrupci ón ▁de ▁práctica mente ▁toda s ▁la s ▁actividades ▁comerciales ▁excep to ▁supermercados ▁y ▁farmacias . ▁El ▁ 6 ▁de ▁marzo , ▁el ▁Co legio ▁italian o ▁de ▁A n este s ia , ▁A n alg esia , ▁Re anima ción ▁y ▁C uidados ▁I ntensivos ▁( SI A A RTI ) ▁publicó ▁recomenda ciones ▁de ▁ética ▁médica ▁sobre ▁ los ▁protocolos ▁de ▁tr iaje ▁que ▁se ▁podría n ▁utilizar .\n",
            "\n",
            "==> tico-19.en-es.en-filtered.en.subword.dev <==\n",
            "▁The ▁use ▁of ▁location ▁data ▁from ▁mobil e ▁phones ▁by ▁governments ▁for ▁this ▁purpose ▁has ▁prompt ed ▁privacy ▁concerns , ▁with ▁Am nes ty ▁In ternational ▁and ▁over ▁ 1 0 0 ▁other ▁organizations ▁issu ing ▁a ▁statement ▁call ing ▁for ▁limit s ▁on ▁this ▁kind ▁of ▁surveillance .\n",
            "\n",
            "==> tico-19.en-es.es-filtered.es.subword.dev <==\n",
            "▁El ▁uso ▁de ▁ los ▁datos ▁de ▁ubicación ▁de ▁ los ▁teléfono s ▁móvil es ▁por ▁parte ▁de ▁ los ▁gobiernos ▁con ▁este ▁prop ó sito ▁ha ▁genera do ▁preocupa ciones ▁acerca ▁de ▁la ▁privacidad , ▁y ▁Am nist ía ▁Internacional ▁y ▁más ▁de ▁otras ▁ 1 0 0 ▁organiza ciones ▁emit ieron ▁una ▁declara ción ▁para ▁exigi r ▁límite s ▁sobre ▁este ▁tipo ▁de ▁vigilancia .\n",
            "\n",
            "==> tico-19.en-es.en-filtered.en.subword.test <==\n",
            "▁Viruses ▁can ▁also ▁infect ▁an ▁individual ▁through ▁the ▁eyes .\n",
            "\n",
            "==> tico-19.en-es.es-filtered.es.subword.test <==\n",
            "▁Lo s ▁virus ▁también ▁puede n ▁infectar ▁a ▁una ▁persona ▁a ▁ trav és ▁de ▁ los ▁ojos .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install OpenNMT-py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQIq_jbEkaIE",
        "outputId": "f5c0deb0-c147-44e0-f236-0c3b338e7d16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: OpenNMT-py in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: torch<2.3,>=2.1 in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (2.2.2)\n",
            "Requirement already satisfied: configargparse in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (1.7)\n",
            "Requirement already satisfied: ctranslate2<5,>=4 in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (4.6.0)\n",
            "Requirement already satisfied: tensorboard>=2.3 in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (2.18.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (3.1.0)\n",
            "Requirement already satisfied: waitress in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (3.0.2)\n",
            "Requirement already satisfied: pyonmttok<2,>=1.37 in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (1.37.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (6.0.2)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (2.5.1)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (3.13.0)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (2.1.0)\n",
            "Requirement already satisfied: fasttext-wheel in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (0.9.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (3.8.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (1.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4->OpenNMT-py) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4->OpenNMT-py) (2.0.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.3->OpenNMT-py) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.3->OpenNMT-py) (5.29.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.3->OpenNMT-py) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (4.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3,>=2.1->OpenNMT-py) (12.5.82)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.11/dist-packages (from fasttext-wheel->OpenNMT-py) (2.13.6)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask->OpenNMT-py) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask->OpenNMT-py) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask->OpenNMT-py) (1.9.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu->OpenNMT-py) (3.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu->OpenNMT-py) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu->OpenNMT-py) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu->OpenNMT-py) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu->OpenNMT-py) (5.3.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (2.11.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.3,>=2.1->OpenNMT-py) (3.0.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->OpenNMT-py) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->OpenNMT-py) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->OpenNMT-py) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->OpenNMT-py) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy->OpenNMT-py) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy->OpenNMT-py) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy->OpenNMT-py) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy->OpenNMT-py) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->OpenNMT-py) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->OpenNMT-py) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->OpenNMT-py) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->OpenNMT-py) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->OpenNMT-py) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->OpenNMT-py) (7.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch<2.3,>=2.1->OpenNMT-py) (1.3.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->OpenNMT-py) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->OpenNMT-py) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->OpenNMT-py) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->OpenNMT-py) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->OpenNMT-py) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/nmt\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeDiwKNXkaEm",
        "outputId": "77bc139a-91e4-43be-e2cf-b39fd0236775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/nmt'\n",
            "/content\n",
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = '''# config.yaml for TICO-19 English-Spanish dataset\n",
        "\n",
        "## Where the samples will be written\n",
        "save_data: run\n",
        "\n",
        "# Training files\n",
        "data:\n",
        "    corpus_1:\n",
        "        path_src: tico-19.en-es.en-filtered.en.subword.train\n",
        "        path_tgt: tico-19.en-es.es-filtered.es.subword.train\n",
        "        transforms: [filtertoolong]\n",
        "    valid:\n",
        "        path_src: tico-19.en-es.en-filtered.en.subword.dev\n",
        "        path_tgt: tico-19.en-es.es-filtered.es.subword.dev\n",
        "        transforms: [filtertoolong]\n",
        "\n",
        "# Vocabulary files, generated by onmt_build_vocab\n",
        "src_vocab: run/source.vocab\n",
        "tgt_vocab: run/target.vocab\n",
        "\n",
        "# Vocabulary size - reduced for small dataset\n",
        "src_vocab_size: 32000\n",
        "tgt_vocab_size: 32000\n",
        "\n",
        "# Filter out source/target longer than n if [filtertoolong] enabled\n",
        "src_seq_length: 150\n",
        "tgt_seq_length: 150\n",
        "\n",
        "# Tokenization options\n",
        "src_subword_model: source.model\n",
        "tgt_subword_model: target.model\n",
        "\n",
        "# Where to save the log file and the output models/checkpoints\n",
        "log_file: train.log\n",
        "save_model: models/model.enes\n",
        "\n",
        "# Stop training if it does not improve after n validations\n",
        "early_stopping: 4\n",
        "\n",
        "# Save a model checkpoint more frequently for small dataset\n",
        "save_checkpoint_steps: 200\n",
        "\n",
        "# To save space, limit checkpoints to last n\n",
        "keep_checkpoint: 5\n",
        "\n",
        "seed: 3435\n",
        "\n",
        "# Reduced training steps for very small dataset\n",
        "train_steps: 1500\n",
        "\n",
        "# Run validation more frequently for small dataset\n",
        "valid_steps: 150\n",
        "\n",
        "# Reduced warmup steps for small dataset\n",
        "warmup_steps: 300\n",
        "report_every: 50\n",
        "\n",
        "# Number of GPUs, and IDs of GPUs\n",
        "world_size: 1\n",
        "gpu_ranks: [0]\n",
        "\n",
        "# Batching - Adjusted for small dataset\n",
        "bucket_size: 65536\n",
        "num_workers: 0  # Set to 0 for small datasets to prevent RAM issues\n",
        "batch_type: \"tokens\"\n",
        "batch_size: 1024   # Smaller batch size for small datasets\n",
        "valid_batch_size: 512\n",
        "max_generator_batches: 2\n",
        "accum_count: [8]  # Increased accumulation for stable gradients\n",
        "accum_steps: [0]\n",
        "\n",
        "# Optimization\n",
        "model_dtype: \"fp16\"\n",
        "optim: \"adam\"\n",
        "learning_rate: 0.5  # Reduced learning rate for small dataset\n",
        "decay_method: \"noam\"\n",
        "adam_beta2: 0.998\n",
        "max_grad_norm: 0\n",
        "label_smoothing: 0.1\n",
        "param_init: 0\n",
        "param_init_glorot: true\n",
        "normalization: \"tokens\"\n",
        "\n",
        "# Model - Modified for small dataset\n",
        "encoder_type: transformer\n",
        "decoder_type: transformer\n",
        "position_encoding: true\n",
        "enc_layers: 4  # Reduced layers for small dataset\n",
        "dec_layers: 4  # Reduced layers for small dataset\n",
        "heads: 8\n",
        "hidden_size: 256  # Reduced dimensions for small dataset\n",
        "word_vec_size: 256  # Reduced dimensions for small dataset\n",
        "transformer_ff: 1024  # Reduced feed-forward size\n",
        "dropout_steps: [0]\n",
        "dropout: [0.3]  # Increased dropout to prevent overfitting\n",
        "attention_dropout: [0.3]  # Increased dropout to prevent overfitting\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "with open(\"config.yaml\", \"w+\") as config_yaml:\n",
        "  config_yaml.write(config)"
      ],
      "metadata": {
        "id": "OtZp8uLckZ9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat config.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtfsgvACuzes",
        "outputId": "a04b62e3-cf73-4200-b744-b7361302cc1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# config.yaml for TICO-19 English-Spanish dataset\n",
            "\n",
            "## Where the samples will be written\n",
            "save_data: run\n",
            "\n",
            "# Training files\n",
            "data:\n",
            "    corpus_1:\n",
            "        path_src: tico-19.en-es.en-filtered.en.subword.train\n",
            "        path_tgt: tico-19.en-es.es-filtered.es.subword.train\n",
            "        transforms: [filtertoolong]\n",
            "    valid:\n",
            "        path_src: tico-19.en-es.en-filtered.en.subword.dev\n",
            "        path_tgt: tico-19.en-es.es-filtered.es.subword.dev\n",
            "        transforms: [filtertoolong]\n",
            "\n",
            "# Vocabulary files, generated by onmt_build_vocab\n",
            "src_vocab: run/source.vocab\n",
            "tgt_vocab: run/target.vocab\n",
            "\n",
            "# Vocabulary size - reduced for small dataset\n",
            "src_vocab_size: 32000\n",
            "tgt_vocab_size: 32000\n",
            "\n",
            "# Filter out source/target longer than n if [filtertoolong] enabled\n",
            "src_seq_length: 150\n",
            "tgt_seq_length: 150\n",
            "\n",
            "# Tokenization options\n",
            "src_subword_model: source.model\n",
            "tgt_subword_model: target.model\n",
            "\n",
            "# Where to save the log file and the output models/checkpoints\n",
            "log_file: train.log\n",
            "save_model: models/model.enes\n",
            "\n",
            "# Stop training if it does not improve after n validations\n",
            "early_stopping: 4\n",
            "\n",
            "# Save a model checkpoint more frequently for small dataset\n",
            "save_checkpoint_steps: 200\n",
            "\n",
            "# To save space, limit checkpoints to last n\n",
            "keep_checkpoint: 5\n",
            "\n",
            "seed: 3435\n",
            "\n",
            "# Reduced training steps for very small dataset\n",
            "train_steps: 1500\n",
            "\n",
            "# Run validation more frequently for small dataset\n",
            "valid_steps: 150\n",
            "\n",
            "# Reduced warmup steps for small dataset\n",
            "warmup_steps: 300\n",
            "report_every: 50\n",
            "\n",
            "# Number of GPUs, and IDs of GPUs\n",
            "world_size: 1\n",
            "gpu_ranks: [0]\n",
            "\n",
            "# Batching - Adjusted for small dataset\n",
            "bucket_size: 65536\n",
            "num_workers: 0  # Set to 0 for small datasets to prevent RAM issues\n",
            "batch_type: \"tokens\"\n",
            "batch_size: 1024   # Smaller batch size for small datasets\n",
            "valid_batch_size: 512\n",
            "max_generator_batches: 2\n",
            "accum_count: [8]  # Increased accumulation for stable gradients\n",
            "accum_steps: [0]\n",
            "\n",
            "# Optimization\n",
            "model_dtype: \"fp16\"\n",
            "optim: \"adam\"\n",
            "learning_rate: 0.5  # Reduced learning rate for small dataset\n",
            "decay_method: \"noam\"\n",
            "adam_beta2: 0.998\n",
            "max_grad_norm: 0\n",
            "label_smoothing: 0.1\n",
            "param_init: 0\n",
            "param_init_glorot: true\n",
            "normalization: \"tokens\"\n",
            "\n",
            "# Model - Modified for small dataset\n",
            "encoder_type: transformer\n",
            "decoder_type: transformer\n",
            "position_encoding: true\n",
            "enc_layers: 4  # Reduced layers for small dataset\n",
            "dec_layers: 4  # Reduced layers for small dataset\n",
            "heads: 8\n",
            "hidden_size: 256  # Reduced dimensions for small dataset\n",
            "word_vec_size: 256  # Reduced dimensions for small dataset\n",
            "transformer_ff: 1024  # Reduced feed-forward size\n",
            "dropout_steps: [0]\n",
            "dropout: [0.3]  # Increased dropout to prevent overfitting\n",
            "attention_dropout: [0.3]  # Increased dropout to prevent overfitting\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nproc --all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnxtUEYXkZ0v",
        "outputId": "927d308f-a999-4211-a0f9-0190257f5212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Vocabulary\n",
        "\n",
        "# -config: path to your config.yaml file\n",
        "# -n_sample: use -1 to build vocabulary on all the segment in the training dataset\n",
        "# -num_threads: change it to match the number of CPUs to run it faster\n",
        "\n",
        "!onmt_build_vocab -config config.yaml -n_sample -1 -num_threads 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVyOu5XwkZn_",
        "outputId": "f0ed789e-2725-4b95-aaf6-79adcaa4646c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/usr/local/bin/onmt_build_vocab\", line 5, in <module>\n",
            "    from onmt.bin.build_vocab import main\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/onmt/__init__.py\", line 2, in <module>\n",
            "    import onmt.inputters\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/onmt/inputters/__init__.py\", line 7, in <module>\n",
            "    from onmt.inputters.text_utils import text_sort_key, process, numericalize, tensorify\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/onmt/inputters/text_utils.py\", line 1, in <module>\n",
            "    import torch\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1477, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2025-04-14 09:58:16,572 INFO] Counter vocab from -1 samples.\n",
            "[2025-04-14 09:58:16,572 INFO] n_sample=-1: Build vocab on full datasets.\n",
            "[2025-04-14 09:58:16,755 INFO] * Transform statistics for corpus_1(50.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=3)\n",
            "\n",
            "[2025-04-14 09:58:16,758 INFO] * Transform statistics for corpus_1(50.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=2)\n",
            "\n",
            "[2025-04-14 09:58:16,802 INFO] Counters src: 5895\n",
            "[2025-04-14 09:58:16,803 INFO] Counters tgt: 6459\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9oNl8A9u-h9",
        "outputId": "ac8e0dd2-a6e2-4a33-841e-1b7d230ce4d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-164a7278-effe-982a-a5f5-6dda818e1cfd)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the GPU is visable to PyTorch\n",
        "\n",
        "import torch\n",
        "\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "\n",
        "gpu_memory = torch.cuda.mem_get_info(0)\n",
        "print(\"Free GPU memory:\", gpu_memory[0]/1024**2, \"out of:\", gpu_memory[1]/1024**2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qOpy_qGu-fk",
        "outputId": "22592a99-dc23-47ab-f3d2-5442f3d77117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Tesla T4\n",
            "Free GPU memory: 14992.125 out of: 15095.0625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf drive/MyDrive/nmt/models/"
      ],
      "metadata": {
        "id": "enK-FZ7Xu-c8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sKodGK1lu-Zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q52R_LIKu-Wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2T0KQMzcu-NL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}